{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 20:21:47.566681: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-21 20:21:48.026544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 20:21:48.778072: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 20:21:48.867227: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 20:21:48.868784: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear arquivos ocultos (.ipny)\n",
    "def filter_hidden_folders(folder_list):\n",
    "    return [folder for folder in folder_list if not folder.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g', 'V', 'W', 'r', 'i', 'a', 'G', 'I', 's', 'J', 'y', 'z', 't', 'c', 'Q', 'u', 'E', 'o', 'H', 'B', 'U', 'N', 'F', 'm', 'n', 'v', 'T', 'D', 'A', 'e', 'w', 'O', '.ipynb_checkpoints', 'S', 'K', 'l', 'C', 'q', 'p', 'Z', 'j', 'h', 'f', 'L', 'M', 'b', 'd', 'P', 'x', 'X', 'Y', 'R', 'k']\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "# Caminho para os dados do dataset e o reescalador de imagens\n",
    "\n",
    "xray_directory = 'font_results/normal'\n",
    "\n",
    "xray_classes = filter_hidden_folders(os.listdir(xray_directory))  # Filtra pastas ocultas\n",
    "print(os.listdir(xray_directory))\n",
    "print(len(os.listdir(xray_directory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 20:21:49.222204: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 20:21:49.223597: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 20:21:49.224903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 20:21:49.316905: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 20:21:49.317941: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 20:21:49.318929: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 20:21:49.320158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10016 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,189</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │            \u001b[38;5;34m30\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m53\u001b[0m)             │        \u001b[38;5;34m27,189\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,004,563</span> (57.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,004,563\u001b[0m (57.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">289,875</span> (1.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m289,875\u001b[0m (1.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Definir parâmetros\n",
    "input_shape = (180, 100, 1)  # Imagem 180x100, 1 canal (grayscale)\n",
    "num_classes = 53  # 26 letras maiúsculas, 26 minúsculas, + 1 \"null\"\n",
    "\n",
    "# Carregar o modelo VGG16 pré-treinado com pesos do ImageNet\n",
    "# Incluir a camada de pooling global (retirar as camadas de classificação final)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(180, 100, 3))\n",
    "\n",
    "# Adaptar a camada de entrada para grayscale (1 canal)\n",
    "# Expanda o canal para 3 (de 1 para 3) para o modelo pré-treinado que usa RGB\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "x = layers.Conv2D(3, (3, 3), padding='same')(inputs)  # Converter 1 canal para 3\n",
    "\n",
    "# Conectar o modelo pré-treinado\n",
    "x = base_model(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Adicionar as camadas de classificação\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Criar o modelo final\n",
    "model = models.Model(inputs, x)\n",
    "\n",
    "# Congelar as camadas do modelo pré-treinado para não treiná-las no início\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Resumo do modelo\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,189</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │            \u001b[38;5;34m30\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m53\u001b[0m)             │        \u001b[38;5;34m27,189\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,004,563</span> (57.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,004,563\u001b[0m (57.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">289,875</span> (1.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m289,875\u001b[0m (1.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o arquivo de treinamento em diferentes epocas\n",
    "\n",
    "# Nome/caminho do arquivo que sera salvo\n",
    "filepath = \"weights_normal_vgg16.keras\" \n",
    "#filepath = \"weights_normal_vgg16.keras\" \n",
    "\n",
    "# Define os parametros para atualizar o arquivo final\n",
    "# ModelCheckpoint(nome_do_arquivo, monitor = 'parametro a ser alalisado', verbose = 1 (imprimir no console quando arquivo for salvo), save_best_only = True, mode = 'min' (objetivo minimizar perda))\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "\n",
    "# Cria uma lista que contém o ModelCheckpoint configurado usado durante o treinamento\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerenciador de imagem para pre processamento\n",
    "# Aumentar a base de dados \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "# Transforma os valores de pixel de (0-255 ->0.0 - 1.0 )  \n",
    "    rescale=1. / 255,\n",
    "# Aplica zoom aleatório às imagens dentro do intervalo especificado (0.2 -> 20%)\n",
    "    zoom_range=0.2,\n",
    "#Este parâmetro é usado para dividir automaticamente os dados em conjuntos de treinamento e validação \n",
    "    validation_split=0.3\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria critério de parada precoce\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2658448 images belonging to 53 classes.\n",
      "Found 1139268 images belonging to 53 classes.\n",
      "{'.ipynb_checkpoints': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26, 'a': 27, 'b': 28, 'c': 29, 'd': 30, 'e': 31, 'f': 32, 'g': 33, 'h': 34, 'i': 35, 'j': 36, 'k': 37, 'l': 38, 'm': 39, 'n': 40, 'o': 41, 'p': 42, 'q': 43, 'r': 44, 's': 45, 't': 46, 'u': 47, 'v': 48, 'w': 49, 'x': 50, 'y': 51, 'z': 52}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 50\n",
    "TARGET_SIZE=(180, 100)\n",
    "CMODE='grayscale'\n",
    "CLASS_MODE='categorical'\n",
    "# Imagens para treinamento\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    xray_directory,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode=CMODE, \n",
    "    class_mode=CLASS_MODE,\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Imagens para validação\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        xray_directory,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        color_mode=CMODE,\n",
    "        class_mode=CLASS_MODE,\n",
    "        shuffle=True,\n",
    "        subset = 'validation'\n",
    "        )\n",
    "print(train_generator.class_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagens:  (50, 180, 100, 1)\n",
      "Labels:  (50, 53)\n"
     ]
    }
   ],
   "source": [
    "# Testar o gerador de dados\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print(\"Imagens: \", data_batch.shape)\n",
    "    print(\"Labels: \", labels_batch.shape)\n",
    "    break  # Apenas testar um batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps_per_epoch = len(train_generator) - 1  # Total de batches por época\n",
    "\n",
    "# treinamento do modelo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/picg/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729552946.450685   18073 service.cc:145] XLA service 0x73463400d890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1729552946.450703   18073 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2024-10-21 20:22:26.472858: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-21 20:22:26.579666: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729552946.945053   18259 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1073', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1729552947.057144   18276 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_868', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1729552947.095324   18274 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1084', 444 bytes spill stores, 444 bytes spill loads\n",
      "\n",
      "I0000 00:00:1729552947.170133   18281 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_868', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1729552947.328850   18259 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1084', 436 bytes spill stores, 436 bytes spill loads\n",
      "\n",
      "I0000 00:00:1729552947.428531   18273 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1075', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    3/53169\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56:30\u001b[0m 64ms/step - accuracy: 0.0400 - loss: 4.0376"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729552954.008287   18073 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1399/53169\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52:25\u001b[0m 61ms/step - accuracy: 0.0911 - loss: 3.6019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729553039.477547   18497 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1084', 436 bytes spill stores, 436 bytes spill loads\n",
      "\n",
      "I0000 00:00:1729553039.501893   18513 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_868', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1729553039.705302   18494 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1084', 428 bytes spill stores, 428 bytes spill loads\n",
      "\n",
      "I0000 00:00:1729553039.920410   18497 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1075', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3516 - loss: 2.3538\n",
      "Epoch 1: loss improved from inf to 1.99205, saving model to weights_normal_vgg16.keras\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3850s\u001b[0m 72ms/step - accuracy: 0.3516 - loss: 2.3538 - val_accuracy: 0.3855 - val_loss: 2.3516\n",
      "Epoch 2/25\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5350 - loss: 1.5979\n",
      "Epoch 2: loss improved from 1.99205 to 1.55530, saving model to weights_normal_vgg16.keras\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3832s\u001b[0m 72ms/step - accuracy: 0.5350 - loss: 1.5979 - val_accuracy: 0.3963 - val_loss: 2.4371\n",
      "Epoch 3/25\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5699 - loss: 1.4621\n",
      "Epoch 3: loss improved from 1.55530 to 1.44675, saving model to weights_normal_vgg16.keras\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3831s\u001b[0m 72ms/step - accuracy: 0.5699 - loss: 1.4621 - val_accuracy: 0.4210 - val_loss: 2.2447\n",
      "Epoch 4/25\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5856 - loss: 1.4017\n",
      "Epoch 4: loss improved from 1.44675 to 1.39059, saving model to weights_normal_vgg16.keras\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3835s\u001b[0m 72ms/step - accuracy: 0.5856 - loss: 1.4017 - val_accuracy: 0.4196 - val_loss: 2.3473\n",
      "Epoch 5/25\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5965 - loss: 1.3607\n",
      "Epoch 5: loss improved from 1.39059 to 1.35358, saving model to weights_normal_vgg16.keras\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3829s\u001b[0m 72ms/step - accuracy: 0.5965 - loss: 1.3607 - val_accuracy: 0.4428 - val_loss: 2.2253\n",
      "Epoch 6/25\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6052 - loss: 1.3309\n",
      "Epoch 6: loss improved from 1.35358 to 1.32732, saving model to weights_normal_vgg16.keras\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3833s\u001b[0m 72ms/step - accuracy: 0.6052 - loss: 1.3309 - val_accuracy: 0.4313 - val_loss: 2.3613\n",
      "Epoch 7/25\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6103 - loss: 1.3094\n",
      "Epoch 7: loss improved from 1.32732 to 1.30819, saving model to weights_normal_vgg16.keras\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3831s\u001b[0m 72ms/step - accuracy: 0.6103 - loss: 1.3094 - val_accuracy: 0.4431 - val_loss: 2.2470\n",
      "Epoch 8/25\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6148 - loss: 1.2933\n",
      "Epoch 8: loss improved from 1.30819 to 1.29164, saving model to weights_normal_vgg16.keras\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3831s\u001b[0m 72ms/step - accuracy: 0.6148 - loss: 1.2933 - val_accuracy: 0.4356 - val_loss: 2.3245\n",
      "Epoch 9/25\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6186 - loss: 1.2804\n",
      "Epoch 9: loss improved from 1.29164 to 1.27871, saving model to weights_normal_vgg16.keras\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3831s\u001b[0m 72ms/step - accuracy: 0.6186 - loss: 1.2804 - val_accuracy: 0.4351 - val_loss: 2.3871\n",
      "Epoch 10/25\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6217 - loss: 1.2681\n",
      "Epoch 10: loss improved from 1.27871 to 1.26686, saving model to weights_normal_vgg16.keras\n",
      "\u001b[1m53169/53169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3833s\u001b[0m 72ms/step - accuracy: 0.6217 - loss: 1.2681 - val_accuracy: 0.4353 - val_loss: 2.3543\n",
      "Epoch 11/25\n",
      "\u001b[1m17459/53169\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m36:17\u001b[0m 61ms/step - accuracy: 0.6246 - loss: 1.2587"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs = 20, validation_data=validation_generator, callbacks=callbacks_list)\n",
    "aux = history\n",
    "history = history.history.keys() #paramestros de avaliação accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de grafico para ver taxa de acerto por taxa de erro \n",
    "plt.plot(aux.history['accuracy'])\n",
    "plt.plot(aux.history['loss'])\n",
    "plt.title('Erro e taxa de acerto durante o treinamento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Taxa de acerto e erro')\n",
    "plt.legend(['Taxa de acerto', 'Erro']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(aux.history)\n",
    "print(hist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o DataFrame em um arquivo CSV\n",
    "hist_df.to_csv('training_history_normal_vgg16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados do CSV\n",
    "loaded_history_df = pd.read_csv('training_history_normal_vgg16.csv')\n",
    "# Exibir os dados carregados (opcional)\n",
    "print(loaded_history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a perda de treinamento e validação\n",
    "plt.plot(loaded_history_df['loss'], label='Loss (train)')\n",
    "plt.plot(loaded_history_df['val_loss'], label='Loss (validation)')\n",
    "plt.title('Loss durante o treinamento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotar a precisão de treinamento e validação\n",
    "plt.plot(loaded_history_df['accuracy'], label='Accuracy (train)')\n",
    "plt.plot(loaded_history_df['val_accuracy'], label='Accuracy (validation)')\n",
    "plt.title('Precisão durante o treinamento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisão')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparação de LOSS e ACCURACY entre as epocas de treino da rede\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loaded_history_df['loss'], label='train loss')\n",
    "plt.plot(loaded_history_df['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loaded_history_df['accuracy'], label='train accuracy')\n",
    "plt.plot(loaded_history_df['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparação de Loss e Accuracy de redes distintas\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def plot_comparison(results, metric='accuracy'):\n",
    "    models = list(results.keys())\n",
    "    final_accuracy = [results[model][metric][-1] for model in models]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(models, final_accuracy)\n",
    "    plt.title(f'Comparação de {metric} entre diferentes redes')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.xlabel('Modelos')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico de curvas para comparação entre redes\n",
    "def plot_comparison_curves(results, metric='accuracy'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    for model, history in results.items():\n",
    "        plt.plot(history[metric], label=f'{model} - train')\n",
    "        plt.plot(history['val_' + metric], '--', label=f'{model} - val')\n",
    "    \n",
    "    plt.title(f'Comparação de {metric.capitalize()} entre Redes')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz Confusão\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Matriz de Confusão - {model_name}')\n",
    "    plt.ylabel('Verdadeiro')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot\n",
    "def plot_boxplot(results, metric='accuracy'):\n",
    "    data = [history[metric] for history in results.values()]\n",
    "    labels = results.keys()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(data, labels=labels)\n",
    "    plt.title(f'Boxplot de {metric.capitalize()} entre Redes')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defini caminho para pasta de teste\n",
    "test_directory = 'dataset/test'\n",
    "# lista contendo os nomes dos arquivos e diretórios presentes no caminho fornecido\n",
    "os.listdir(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mudar a escala das imagens\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_gen.flow_from_directory(batch_size = 13, directory = test_directory,\n",
    "                                              shuffle = True, target_size = (256, 256),\n",
    "                                              class_mode = 'categorical')\n",
    "\n",
    "evaluate = model.evaluate(test_generator)\n",
    "\n",
    "len(os.listdir(test_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplica a rede treinada em um conjunto de teste de imagens e armazena os resultados\n",
    "prediction = []\n",
    "original = []\n",
    "image = []\n",
    "\n",
    "# percorre as subpastas no diretório test_directory, assumindo que cada subpasta contém imagens de uma determinada classe\n",
    "for i in range(len(os.listdir(test_directory))):\n",
    "  # percorre os arquivos dentro de cada subpasta e processa cada imagem\n",
    "  for item in os.listdir(os.path.join(test_directory, str(i))):\n",
    "    \n",
    "    #Etapas de processamento de img\n",
    "\n",
    "    img = cv2.imread(os.path.join(test_directory, str(i), item))\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    image.append(img)\n",
    "    img = img / 255\n",
    "    img = img.reshape(-1, 256, 256, 3)\n",
    "\n",
    "    #rede neural aplicada\n",
    "    predict = model.predict(img)\n",
    "    predict = np.argmax(predict)\n",
    "    prediction.append(predict)\n",
    "    original.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(original, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(12,12))\n",
    "axes = axes.ravel()\n",
    "for i in np.arange(0, 25):\n",
    "  axes[i].imshow(image[i])\n",
    "  axes[i].set_title('Previsão={}\\nTrue={}'.format(str(labels_names[prediction[i]]), str(labels_names[original[i]])))\n",
    "  axes[i].axis('off')\n",
    "plt.subplots_adjust(wspace = 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_names = {0: 'SoldasCorretas', 1: 'SoldasErradas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregar o modelo previamente salvo\n",
    "model_load = load_model('weights.keras')\n",
    "\n",
    "# Carregar a imagem e convertê-la para um array numpy em escala de cinza\n",
    "image = np.array(Image.open(\"/home/picg/TCC/GeradorBase/font_results/normal/a/a-mas-GrandHotel-Regular.png\").convert('L'))\n",
    "\n",
    "# Redimensionar a imagem para o tamanho esperado pela CNN (supondo 180x100)\n",
    "temp_resized = cv2.resize(image, (180, 100))\n",
    "\n",
    "print(temp_resized.shape)\n",
    "\n",
    "# Normalizar os valores dos pixels para [0, 1]\n",
    "normalized = temp_resized / 255.0\n",
    "\n",
    "# Adicionar uma dimensão para corresponder ao formato de entrada esperado pelo modelo\n",
    "final = normalized.reshape(1, 180, 100, 1)  # '1' aqui é o batch size\n",
    "\n",
    "# Fazer a predição com o modelo carregado\n",
    "prediction = model_load.predict(final)\n",
    "\n",
    "# Exibir o resultado da predição\n",
    "print(\"Predição:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temp_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = np.array(Image.open(\"/home/picg/TCC/GeradorBase/font_results/normal/a/a-mam-GrandHotel-Regular.png\"))\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Achar a classe com maior probabilidade\n",
    "predicted_class = np.argmax(prediction)\n",
    "'''\n",
    "{'.ipynb_checkpoints': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26, 'a': 27, 'b': 28, 'c': 29, 'd': 30, 'e': 31, 'f': 32, 'g': 33, 'h': 34, 'i': 35, 'j': 36, 'k': 37, 'l': 38, 'm': 39, 'n': 40, 'o': 41, 'p': 42, 'q': 43, 'r': 44, 's': 45, 't': 46, 'u': 47, 'v': 48, 'w': 49, 'x': 50, 'y': 51, 'z': 52}\n",
    "'''\n",
    "\n",
    "# Definir labels (saidas) \n",
    "labels_names = {0: '.ipynb_checkpoints', \n",
    "                1: 'a',\n",
    "                2: 'A',\n",
    "                3: 'b',\n",
    "                4: 'B',\n",
    "                5: 'c',\n",
    "                6: 'C',\n",
    "                7: 'd',\n",
    "                8: 'D',\n",
    "                9: 'e',\n",
    "                10: 'E', \n",
    "                11: 'f',\n",
    "                12: 'F',\n",
    "                13: 'g',\n",
    "                14: 'G',\n",
    "                15: 'h',\n",
    "                16: 'H',\n",
    "                17: 'i',\n",
    "                18: 'I',\n",
    "                19: 'j',\n",
    "                20: 'J', \n",
    "                21: 'k',\n",
    "                22: 'K',\n",
    "                23: 'l',\n",
    "                24: 'L',\n",
    "                25: 'm',\n",
    "                26: 'M',\n",
    "                27: 'n',\n",
    "                28: 'N',\n",
    "                29: 'o',\n",
    "                30: 'O', \n",
    "                31: 'p',\n",
    "                32: 'P',\n",
    "                33: 'q',\n",
    "                34: 'Q',\n",
    "                35: 'r',\n",
    "                36: 'R',\n",
    "                37: 's',\n",
    "                38: 'S',\n",
    "                39: 't',\n",
    "                40: 'T', \n",
    "                41: 'u',\n",
    "                42: 'U',\n",
    "                43: 'v',\n",
    "                44: 'V',\n",
    "                45: 'w',\n",
    "                46: 'W',\n",
    "                47: 'x',\n",
    "                48: 'X',\n",
    "                49: 'y',\n",
    "                50: 'Y', \n",
    "                51: 'z',\n",
    "                52: 'Z',\n",
    "                }\n",
    "\n",
    "print(f\"A classe prevista é - {predicted_class}: {labels_names[predicted_class]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
